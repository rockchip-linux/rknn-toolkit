# RKNN OP Support
Base on RKNN Toolkit Version 1.6.0

## Caffe OPs supported by RKNN
There are two caffe protocols RKNN Toolkit uses, one based on the officially modified protocol of berkeley, and one based on the protocol containing the LSTM layer.  
The protocol based on the official revision of berkeley comes from [berkeley caffe](https://github.com/BVLC/caffe/tree/master/src/caffe/proto "Berkeley Caffe"), commit hash is 21d0608. On this basis RKNN Toolkit have added some OPs.  
The protocol containing the LSTM layer refers to [warpctc caffe](https://github.com/xmfbit/warpctc-caffe/tree/master/src/caffe/proto "warpctc caffe"), commit hash is bd6181b.  
Based on these protocols, the list of Caffe OPs supported by RKNN Version 1.6.0 is as follows:

| **Operators** |
|---|
|deconvolution|
|convolutiondepthwise|
|convolution|
|pooling|
|poolwithargmax|
|innerproduct|
|slice|
|concat|
|reshape|
|flatten|
|permute|
|reorg|
|reverse|
|scale|
|relu|
|leakyrelu|
|softmax|
|prelu|
|sigmoid|
|tanh|
|batchnorm|
|bn|
|normalize|
|lrn|
|resize|
|lstm|
|roipooling|
|shufflechannel|
|proposal|
|dropout|
|eltwise|
|split|
|l2normalizescale|
|absval|
|axpy|
|upsample|

## Keras OPs supported by RKNN
The list of Keras OPs supported by RKNN Version 1.6.0 is as follows:

| **Operators** |
|---|
|Dense|
|Flatten|
|Reshape|
|LSTM|
|GRU|
|SimpleRNN|
|Embedding|
|BatchNormalization|
|BatchNormalizationV1|
|Conv2D|
|Activation|
|Add|
|ZeroPadding2D|
|MaxPooling2D|
|AveragePooling2D|
|GlobalAveragePooling2D|
|GlobalMaxPooling2D|
|ReLU|
|Softmax|
|LeakyReLU|
|PReLU|
|ThresholdedReLU|
|Conv1D|
|Conv2DTranspose|
|DepthwiseConv2D|
|SeparableConv2D|
|UpSampling2D|
|Dropout|
|Subtract|
|Multiply|
|Concatenate|
|Cropping2D|
|RNN|

## MXNet OPs supported by RKNN
The MXNet version supported by RKNN Toolkit is between 1.4.0 and 1.5.1, models generated by other versions may not support.  
The list of MXNet OPs supported by RKNN Version 1.6.0 is as follows:

| **Operators** |
|---|
|Pooling|
|_contrib_AdaptiveAvgPooling2D|
|Convolution|
|Deconvolution|
|FullyConnected|
|slice|
|slice_axis|
|Crop|
|Concat|
|Reshape|
|Flatten|
|transpose|
|reverse|
|elemwise_add|
|_plus_scalar|
|_minus_scalar|
|elemwise_mul|
|_mul_scalar|
|broadcast_mul|
|_div_scalar|
|relu|
|clip|
|LeakyReLU|
|leaky|
|softmax|
|SoftmaxActivation|
|prelu|
|sigmoid|
|tanh|
|BatchNorm|
|_contrib_BilinearResize2D|
|UpSampling|

## ONNX OPs supported by RKNN
The ONNX version supported by RKNN Toolkit is 1.6.0. According to [ONNX official instructions](https://github.com/microsoft/onnxruntime/blob/master/docs/Versioning.md "ONNX Version Description"), the corresponding ONNX opset version is 11 and the corresponding onnx ir version is 6.  
The list of ONNX OPs supported by RKNN Version 1.6.0 is as follows:

| **Operators** |
|---|
|AveragePool/GlobalAveragePool|
|Conv|
|ConvTranspose|
|MaxPool/GlobalMaxPool|
|Gemm|
|MatMul|
|Slice|
|Split|
|Concat|
|Reshape|
|Flatten|
|Squeeze|
|Transpose|
|DepthToSpace|
|SpaceToDetph|
|Add|
|Sum|
|Sub|
|Mul|
|Div|
|Relu|
|Relu6|
|Clip|
|LeakyRelu|
|Softmax|
|PRelu|
|Floor|
|BatchNormalization|
|LRN|
|Tanh|
|Elu|
|Sigmoid|
|Unsqueeze|
|LogSoftmax|
|Dropout|
|InstanceNormalization|
|Sqrt|
|Log|
|Cast|
|Exp|
|Identity|
|Upsample|
|ReduceMean|
|ReduceMax|
|ReduceMin|
|ReduceSum|
|Gather|
|LSTM|
|GRU|


## Pytorch OPs supported by RKNN
The Pytorch version supported by RKNN Toolkit is between 1.0.0 and 1.2.0, models generated by other versions may not support.  
The list of Pytorch OPs supported by RKNN Version 1.6.0 is as follows:

| **Operators** |
|---|
|aten::adaptive_avg_pool2d|
|aten::add|
|aten::add_|
|aten::addmm|
|aten::avg_pool2d|
|aten::batch_norm|
|aten::cat|
|aten::chunk|
|aten::clone|
|aten::constant_pad_nd|
|aten::contiguous|
|aten::_convolution|
|aten::div|
|aten::dropout|
|aten::dropout_|
|aten::elu|
|aten::elu_|
|aten::exp|
|aten::exp_|
|aten::feature_dropout|
|aten::feature_dropout_|
|aten::flatten|
|aten::floor_divide|
|aten::hardtanh|
|aten::hardtanh_|
|aten::leaky_relu|
|aten::leaky_relu_|
|aten::log|
|aten::log_softmax|
|aten::mm|
|aten::matmul|
|aten::max_pool2d|
|aten::max_pool2d_with_indices|
|aten::mean|
|aten::mul|
|aten::ones|
|aten::permute|
|aten::pixel_shuffle|
|aten::prelu|
|aten::relu|
|aten::relu_|
|aten::reshape|
|aten::rsqrt|
|aten::select|
|aten::sigmoid|
|aten::size|
|aten::slice|
|aten::softmax|
|aten::sqrt|
|aten::squeeze|
|aten::stack|
|aten::sub|
|aten::sum|
|aten::tanh|
|aten::threshold|
|aten::threshold_|
|aten::transpose|
|aten::unsqueeze|
|aten::upsample_nearest2d|
|aten::upsample_bilinear2d|
|aten::view|
|aten::zeros|


## TensorFlow OPs supported by RKNN
In compliance with semantic version, saved models written with one version of TensorFlow can be loaded and evaluated with a later version of TensorFlow with the same major release. So in theory, the pb files (contain OPs belows) generated by TensorFlow before version 1.14.0 are supported by RKNN Toolkit. For more information on TensorFlow version compatibility, please refer to [tensorflow official instructions on OP version](https://www.tensorflow.org/guide/versions "Tensorflow official instructions on OP version") .  
The list of TensorFlow OPs supported by RKNN is as follows:

| **Operators** |
|---|
|tf.layers.dense|
|tf.nn.avg_pool|
|tf.nn.conv2d|
|tf.nn.conv2d_transposed|
|tf.nn.depthwise_conv2d|
|tf.nn.atrous_conv2d|
|tf.nn.max_pool|
|tf.nn.max_pool_with_argmax|
|tf.matmul|
|tf.batch_matmul|
|tf.nn.slice|
|tf.split|
|tf.nn.concat|
|tf.reshape|
|tf.layers.flatten|
|tf.squeeze|
|tf.transpose|
|tf.depth_to_space|
|tf.space_to_depth|
|tf.space_to_batch|
|tf.batch_to_space|
|tf.nn.pad|
|tf.reduce_mean|
|tf.reduce_sum|
|tf.reverse|
|tf.strided_slice|
|tf.add|
|tf.sub|
|tf.mul|
|tf.div|
|tf.less|
|tf.nn.relu|
|tf.nn.relu6|
|tf.nn.leaky_relu|
|tf.nn.softmax|
|tf.nn.sigmoid|
|tf.nn.tanh|
|tf.nn.elu|
|tf.floor|
|tf.sqrt|
|tf.rsqrt|
|tf.exp|
|tf.nn.batch_normalization|
|tf.nn.fused_batch_norm|
|tf.contrib.layers.instance_norm|
|tf.nn.l2_norm|
|tf.nn.local_response_normalization|
|tf.image.resize_bilinear|
|tf.image.resize_nearest_neighor|
|tf.keras.layers.LSTM|
|tf.keras.layers.RNN|
|tf.signal.frame|
|tf.nn.embedding_lookup|
|tf.argmax|
|tf.argmin|
|tf.reducemax|

## TensorFlow Lite OPs supported by RKNN
RKNN Toolkit uses the TF Lite schema commits in link: 
https://github.com/tensorflow/tensorflow/commits/master/tensorflow/lite/schema/schema.fbs  
Commit hash: 0c4f5dfea4ceb3d7c0b46fc04828420a344f7598.  
Because TF Lite schema may not compatible with each other, TF Lite models with older or newer schema may not be loaded successfully.  
The list of TensorFlow Lite OPs supported by RKNN is as follows:

| **Operators** |
|---|
|AVERAGE_POOL_2D|
|CONV_2D|
|CONV_2D_TRANSPOSE|
|DEPTHWISE_CONV_2D|
|CONV_2D|
|MAX_POOL_2D|
|L2_POOL_2D|
|FULLY_CONNECTED|
|SPLIT/SPLIT_V|
|CONCATENATION|
|RESHAPE|
|RESHAPE|
|SQUEEZE|
|TRANSPOSE|
|DEPTH_TO_SPACE|
|SPACE_TO_DEPTH|
|SPACE_TO_BATCH_ND|
|BATCH_TO_SPACE_ND|
|PAD|
|STRIDED_SLICE|
|ADD|
|SUB|
|MUL|
|DIV|
|GREATER|
|GREATER_EQUAL|
|LESS|
|LESS_EQUAL|
|NOT_EQUAL|
|POW|
|FLOOR_DIV|
|SELECT|
|RELU|
|RELU_N1_TO_1|
|RELU1|
|RELU6|
|LEAKY_RELU|
|SOFTMAX|
|PRELU|
|LOGISTIC|
|TANH|
|FLOOR|
|SQRT|
|RSQRT|
|LOG_SOFTMAX|
|NEG|
|L2_NORMALIZATION|
|LOCAL_RESPONSE_NORMALIZATION|
|RESIZE_BILINEAR|
|RESIZE_NEAREST_NEIGHBOR|
|LSTM|
|DEQUANTIZE|
|SVDF|
|REDUCE_MAX|
|REDUCE_MIN|
|ARG_MAX|
|ARG_MIN|
|GATHER|
|TILE|
|UNIDIRECTIONAL_SEQUENCE_LSTM|
|UNPACK|
